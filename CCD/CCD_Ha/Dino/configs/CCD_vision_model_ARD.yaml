global:
  name: CCD_finetune_100epochs_ArtText
  phase: train
  stage: train-supervised
  workdir: workdir
  seed: ~

output_dir: './saved_models/'

dataset:
  scheme: supervised
  type: ST
  train: {
    roots: [
        '../../data/ATTW/artonly/lmdb/train_filtered/',
        # 'xxx/data_lmdb/training/ARD/TextOCR',
        # 'xxx/data_lmdb/training/ARD/Openimages',
    ],
    batch_size: 48,
  }
  valid: {
    roots: [
        '../../data/ATTW/artonly/lmdb/test_filtered/'
        # 'xxx/data_lmdb/validation'
    ],
    batch_size: 48
  }
  test: {
    roots: [
        '../../data/ATTW/artonly/lmdb/test_filtered/'
        # "xxx/data_lmdb/evaluation/benchmark/IIIT5k_3000",
        # "xxx/data_lmdb/evaluation/benchmark/SVT",
        # "xxx/data_lmdb/evaluation/benchmark/IC13_1015",
        # "xxx/data_lmdb/evaluation/benchmark/IC15_1811",
        # "xxx/data_lmdb/evaluation/benchmark/SVTP",
        # "xxx/data_lmdb/evaluation/benchmark/CUTE80",
        # "xxx/data_lmdb/evaluation/benchmark/COCOText",
        # "xxx/data_lmdb/evaluation/benchmark/CTW",
        # "xxx/data_lmdb/evaluation/benchmark/TotalText",
        # "xxx/data_lmdb/evaluation/benchmark/HOST",
        # "xxx/data_lmdb/evaluation/benchmark/WOST",
    ],
    batch_size: 48
  }
  data_aug: True
  multiscales: False
  mask: False
  num_workers: 8
  augmentation_severity: 0
  charset_type: 'DICTVI'

training:
  epochs: 100
  start_iters: 0
  show_iters: 100
  eval_iters: 5000
  save_iters: 5000

model:
  # pretrain_checkpoint: './saved_models/pre_small_65536/checkpoint.pth'
  # pretrain_checkpoint: '../../../data/CCD/Small_ARD_checkpoint.pth'
  # checkpoint: '../../../data/CCD/Small_ARD_checkpoint.pth'
  checkpoint: 'saved_models/CCD_finetune_100epochs_ArtText/10000.pth'

decoder:
  type: 'NRTRDecoder'
  n_layers: 6
  d_embedding: 512
  n_head: 8
  d_model: 512
  d_inner: 256
  d_k: 64
  d_v: 64
  num_classes: 226 #92
  max_seq_len: 25
  start_idx: 224 #91
  padding_idx: 225 #92

mp:
  num: 4

arch: 'vit_small'
patch_size: 4
out_dim: 65536
weight_decay: 0.05
clip_grad: ~
lr: 0.0005
warmup_epochs: 1
min_lr: 0.000001
optimizer: adamw
drop_path_rate: 0.1
seed: 0
num_workers: 8


