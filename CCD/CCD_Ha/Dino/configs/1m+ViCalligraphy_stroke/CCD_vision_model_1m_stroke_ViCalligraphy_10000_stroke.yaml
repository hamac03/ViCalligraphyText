global:
  name: CCD_finetune_1m_stroke_vicalligraphy_10000_stroke_len_40_v1
  phase: train
  stage: train-supervised
  workdir: workdir
  seed: ~

output_dir: './saved_models/'

dataset:
  scheme: supervised
  type: ST
  train: {
    roots: [
      # Bộ 10 000 này bao gồm cả 3000 Vni và 7000 Uniode + ViCalligraphy
      /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/ViCalligraphy-Augment/ViCalligrphy_3000_VNI_7000_Unicode/training
      # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Synth/3000_VNI_7000_Unicode/train_2000_images
      # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke_new/training
      # 'Dino/training_eval_ViCalligraphy/training'
        # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke/train_stroke
        # 'xxx/data_lmdb/training/ARD/TextOCR',
        # 'xxx/data_lmdb/training/ARD/Openimages',
    ],
    batch_size: 42,
  }
  valid: {
    roots: [
      /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/evaluation/calligraphy
      # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke_new/evaluation
      # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke_new/training
      # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/evaluation/calligraphy/
        # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke/test_stroke
        # 'lmdb/test_filtered'
        # 'xxx/data_lmdb/validation'
    ],
    batch_size: 42
  }
  test: {
    roots: [
      # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke_new/evaluation
      /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/evaluation/calligraphy/
        # /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vicalligraphy/ViCalligraphy/lmdb_stroke/test_stroke
        # 'lmdb/test_filtered'
        # "xxx/data_lmdb/evaluation/benchmark/IIIT5k_3000",
        # "xxx/data_lmdb/evaluation/benchmark/SVT",
        # "xxx/data_lmdb/evaluation/benchmark/IC13_1015",
        # "xxx/data_lmdb/evaluation/benchmark/IC15_1811",
        # "xxx/data_lmdb/evaluation/benchmark/SVTP",
        # "xxx/data_lmdb/evaluation/benchmark/CUTE80",
        # "xxx/data_lmdb/evaluation/benchmark/COCOText",
        # "xxx/data_lmdb/evaluation/benchmark/CTW",
        # "xxx/data_lmdb/evaluation/benchmark/TotalText",
        # "xxx/data_lmdb/evaluation/benchmark/HOST",
        # "xxx/data_lmdb/evaluation/benchmark/WOST",
    ],
    batch_size: 42
  }
  data_aug: True
  multiscales: False
  mask: False
  num_workers: 8
  augmentation_severity: 0
  charset_type: 'DICTVI'

training:
  epochs: 100
  start_iters: 0
  show_iters: 5000
  eval_iters: 5000
  save_iters: 5000

model:
  # pretrain_checkpoint: 'saved_models/CCD_finetune_100epochs_ATTW_VNArtText_eval_longlb/6000.pth'
  # pretrain_checkpoint: '../../../data/CCD/Base_ARD_checkpoint.pth'
  # checkpoint: '../../../data/CCD/Small_ARD_checkpoint.pth'
  # checkpoint: 'saved_models/CCD_finetune_100epochs_ArtText/10000.pth'
  # checkpoint: '/mlcv2/WorkingSpace/Personal/hamh/Ha/Methods/CCD/CCD_Ha/saved_models/CCD_finetune_35epochs_1m/best_accuracy.pth'
  # checkpoint: 'saved_models/CCD_finetune_100epochs_ViCalligraphy_base/best_accuracy.pth'
  # checkpoint: pretrained_model/Base_ARD_checkpoint.pth
  checkpoint: saved_models/CCD_finetune_35epochs_1m_stroke/best_accuracy.pth


decoder:
  type: 'NRTRDecoder'
  n_layers: 6
  d_embedding: 512
  n_head: 8
  d_model: 512
  d_inner: 256
  d_k: 64
  d_v: 64
  num_classes: 226 #92
  max_seq_len: 40
  start_idx: 224 #91
  padding_idx: 225 #92

mp:
  num: 4

arch: 'vit_base'
patch_size: 4
out_dim: 65536
weight_decay: 0.05
clip_grad: ~
lr: 0.0005
warmup_epochs: 1
min_lr: 0.0000001
optimizer: adamw
drop_path_rate: 0.1
seed: 0
num_workers: 13
dataset_case_sensitive: True
dataset_eval_case_sensitive: True

