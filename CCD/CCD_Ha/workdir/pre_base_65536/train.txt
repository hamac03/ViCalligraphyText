ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = xxx/data_lmdb/Mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = ['xxx/data_lmdb/evaluation/benchmark', 'xxx/data_lmdb/evaluation/addition']
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['xxx/data_lmdb/validation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_mask
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 10
	(82): warmup_epochs = 10
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 20833
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 48
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
Construct dataset.
each epoch iteration: 10416
each epoch iteration: 10416
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 32
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 31250
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
each epoch iteration: 62500
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 32
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 32
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
Construct dataset.
each epoch iteration: 15625
each epoch iteration: 15625
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 3000
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 50000
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
Construct dataset.
each epoch iteration: 31250
each epoch iteration: 31250
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 200
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 200
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = []
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 200
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 200
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
Construct dataset.
each epoch iteration: 31250
each epoch iteration: 31250
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Methods/CCD/CCD_Ha/Dino/training_eval_ViCalligraphy/evaluation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 200
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 200
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Methods/CCD/CCD_Ha/Dino/training_eval_ViCalligraphy/evaluation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 10
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 200
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 200
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
Construct dataset.
each epoch iteration: 31250
each epoch iteration: 31250
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Methods/CCD/CCD_Ha/Dino/training_eval_ViCalligraphy/evaluation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 1
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 200
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 200
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
ModelConfig(
	(0): arch = vit_base
	(1): batch_size_per_gpu = 16
	(2): clip_grad = 3.0
	(3): crops_number = 2
	(4): dataset_augmentation_severity = 5
	(5): dataset_case_sensitive = False
	(6): dataset_charset_path = ./Dino/data/charset_36.txt
	(7): dataset_data_aug = True
	(8): dataset_eval_case_sensitive = False
	(9): dataset_filter_single_punctuation = False
	(10): dataset_image_height = 32
	(11): dataset_image_width = 128
	(12): dataset_mask = True
	(13): dataset_mask_path = /mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_masks
	(14): dataset_max_length = 25
	(15): dataset_multiscales = False
	(16): dataset_num_workers = 8
	(17): dataset_pin_memory = True
	(18): dataset_portion = 1.0
	(19): dataset_scheme = selfsupervised_kmeans
	(20): dataset_smooth_factor = 0.1
	(21): dataset_smooth_label = False
	(22): dataset_test_batch_size = 128
	(23): dataset_test_roots = []
	(24): dataset_train_batch_size = 128
	(25): dataset_train_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Data/Vi_Synthtiger_1M/lmdb_images']
	(26): dataset_train_weights = None
	(27): dataset_type = ST
	(28): dataset_use_sm = False
	(29): dataset_valid_batch_size = 128
	(30): dataset_valid_roots = ['/mlcv2/WorkingSpace/Personal/hamh/Ha/Methods/CCD/CCD_Ha/Dino/training_eval_ViCalligraphy/evaluation']
	(31): dist_url = env://
	(32): drop_path_rate = 0.1
	(33): epochs = 100
	(34): freeze_last_layer = 1
	(35): global_crops_scale = (0.4, 1.)
	(36): global_debug = False
	(37): global_name = pre_base_65536
	(38): global_phase = train
	(39): global_seed = None
	(40): global_stage = pretrain-vision
	(41): global_workdir = workdir/pre_base_65536
	(42): imgnet_based = 1000000
	(43): local_crops_number = 8
	(44): local_crops_scale = (0.05, 0.4)
	(45): local_rank = 0
	(46): lr = 0.0005
	(47): min_lr = 1e-06
	(48): model_checkpoint = None
	(49): model_name = Dino.model.dino_vision.ABIDINOModel
	(50): model_seg_channel = 512
	(51): model_strict = True
	(52): momentum_teacher = 0.9995
	(53): mp_num = 4
	(54): norm_last_layer = True
	(55): num_workers = 12
	(56): optimizer = adamw
	(57): optimizer_args_betas = (0.9, 0.999)
	(58): optimizer_bn_wd = False
	(59): optimizer_clip_grad = 20
	(60): optimizer_lr = 0.0001
	(61): optimizer_scheduler_gamma = 0.1
	(62): optimizer_scheduler_periods = [3, 1, 1]
	(63): optimizer_true_wd = False
	(64): optimizer_type = Adam
	(65): optimizer_wd = 0.0
	(66): out_dim = 65536
	(67): output_dir = ./saved_models/
	(68): patch_size = 4
	(69): saveckp_freq = 1
	(70): seed = 0
	(71): teacher_temp = 0.04
	(72): training_epochs = 3
	(73): training_eval_iters = 200
	(74): training_hist_iters = 10000000
	(75): training_save_iters = 200
	(76): training_show_iters = 200
	(77): training_start_iters = 0
	(78): training_stats_iters = 1000
	(79): use_bn_in_head = False
	(80): use_fp16 = False
	(81): warmup_epoch = 0.4
	(82): warmup_epochs = 0.4
	(83): warmup_teacher_temp = 0.04
	(84): warmup_teacher_temp_epochs = 0
	(85): weight_decay = 0.04
	(86): weight_decay_end = 0.4
)
Construct dataset.
Construct dataset.
each epoch iteration: 31250
each epoch iteration: 31250
